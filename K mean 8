import numpy as np
import matplotlib.pyplot as plt
import random

class KMeansScratch:
    def __init__(self, k=3, max_iters=100, random_state=42):
        self.k = k
        self.max_iters = max_iters
        self.random_state = random_state
        self.centroids = None
        self.labels = None
        self.inertia_ = None
        
    def initialize_centroids(self, X):
        np.random.seed(self.random_state)
        random_indices = np.random.choice(X.shape[0], self.k, replace=False)
        return X[random_indices]
    
    def assign_clusters(self, X, centroids):
        distances = np.zeros((X.shape[0], self.k))
        for i in range(self.k):
            distances[:, i] = np.linalg.norm(X - centroids[i], axis=1)
        return np.argmin(distances, axis=1)
    
    def update_centroids(self, X, labels):
        centroids = np.zeros((self.k, X.shape[1]))
        for i in range(self.k):
            cluster_points = X[labels == i]
            if len(cluster_points) > 0:
                centroids[i] = cluster_points.mean(axis=0)
        return centroids
    
    def calculate_inertia(self, X, labels, centroids):
        inertia = 0
        for i in range(self.k):
            cluster_points = X[labels == i]
            if len(cluster_points) > 0:
                inertia += np.sum(np.linalg.norm(cluster_points - centroids[i], axis=1)**2)
        return inertia
    
    def fit(self, X):
        self.centroids = self.initialize_centroids(X)
        
        for iteration in range(self.max_iters):
            old_centroids = self.centroids.copy()
            
            # Assignment step
            self.labels = self.assign_clusters(X, self.centroids)
            
            # Update step
            self.centroids = self.update_centroids(X, self.labels)
            
            # Check for convergence
            if np.allclose(old_centroids, self.centroids):
                break
        
        self.inertia_ = self.calculate_inertia(X, self.labels, self.centroids)
        return self

# Generate synthetic dataset
np.random.seed(42)
n_samples = 300

# Create 3 distinct clusters
cluster1 = np.random.normal(loc=[2, 2], scale=0.5, size=(100, 2))
cluster2 = np.random.normal(loc=[8, 3], scale=0.6, size=(100, 2))
cluster3 = np.random.normal(loc=[5, 8], scale=0.4, size=(100, 2))

X = np.vstack([cluster1, cluster2, cluster3])

# Test K values from 2 to 6
inertia_values = []
k_values = range(2, 7)

print("K-Means Clustering Results")
print("=" * 40)

for k in k_values:
    kmeans = KMeansScratch(k=k, random_state=42)
    kmeans.fit(X)
    inertia_values.append(kmeans.inertia_)
    print(f"K = {k}: Inertia (WCSS) = {kmeans.inertia_:.2f}")

# Text-based elbow plot
print("\nText-based Elbow Plot:")
print("=" * 30)
max_inertia = max(inertia_values)
min_inertia = min(inertia_values)

for i, (k, inertia) in enumerate(zip(k_values, inertia_values)):
    # Normalize inertia to create a simple bar plot
    bar_length = int(20 * (inertia - min_inertia) / (max_inertia - min_inertia)) + 1
    bar = '█' * bar_length
    print(f"K={k}: {bar} ({inertia:.2f})")

# Determine optimal K (using simple elbow detection)
optimal_k = 3  # Based on visual inspection of the synthetic data

# Visualize with optimal K
kmeans_optimal = KMeansScratch(k=optimal_k, random_state=42)
kmeans_optimal.fit(X)

plt.figure(figsize=(12, 4))

# Plot 1: Original data
plt.subplot(1, 2, 1)
plt.scatter(X[:, 0], X[:, 1], alpha=0.7, c='blue')
plt.title('Original Synthetic Data')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.grid(True, alpha=0.3)

# Plot 2: Clustered data
plt.subplot(1, 2, 2)
colors = ['red', 'green', 'blue', 'orange', 'purple', 'brown']
for i in range(optimal_k):
    cluster_points = X[kmeans_optimal.labels == i]
    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], 
                alpha=0.7, c=colors[i], label=f'Cluster {i+1}')
    
plt.scatter(kmeans_optimal.centroids[:, 0], kmeans_optimal.centroids[:, 1], 
            marker='X', s=200, c='black', linewidths=2, label='Centroids')
plt.title(f'K-Means Clustering (K={optimal_k})')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Print final results
print(f"\nOptimal K selected: {optimal_k}")
print(f"Final inertia with K={optimal_k}: {kmeans_optimal.inertia_:.2f}")
K-Means Clustering Results
========================================
K = 2: Inertia (WCSS) = 431.32
K = 3: Inertia (WCSS) = 169.16
K = 4: Inertia (WCSS) = 134.82
K = 5: Inertia (WCSS) = 111.61
K = 6: Inertia (WCSS) = 94.82

Text-based Elbow Plot:
==============================
K=2: ██████████████████ (431.32)
K=3: ████████ (169.16)
K=4: ██████ (134.82)
K=5: ████ (111.61)
K=6: ██ (94.82)

Optimal K selected: 3
Final inertia with K=3: 169.16
